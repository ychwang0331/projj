{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ca545480",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+-----------------+--------------------+---+----------+---------+---------+-----------+-------------------+-------+---------+---------+--------+----------------+--------------+------------------------+---------+-----------+-------------+---------+---------+-------------+------------------+----------+--------------------+---------------+----+--------+-------+---------+---------+------+----+------------------+-------------------+--------------------------+-----------------------+-----------------+---------------+-----------+-----------------+------------------+------------------+---------------------+---------------------+----------------+------------------+----------------+----------------+-------------+-------------+--------------+----------------+--------------------+-----------------------+---------------------+----------------+-------------------+-------------------+-----------------+-------------------------+------------------------+------------------+--------------------+-------------------+-----------------------+--------------------+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+\n",
      "|sofifa_id|          player_url|       short_name|           long_name|age|       dob|height_cm|weight_kg|nationality|               club|overall|potential|value_eur|wage_eur|player_positions|preferred_foot|international_reputation|weak_foot|skill_moves|    work_rate|body_type|real_face|team_position|team_jersey_number|    joined|contract_valid_until|nation_position|pace|shooting|passing|dribbling|defending|physic|year|attacking_crossing|attacking_finishing|attacking_heading_accuracy|attacking_short_passing|attacking_volleys|skill_dribbling|skill_curve|skill_fk_accuracy|skill_long_passing|skill_ball_control|movement_acceleration|movement_sprint_speed|movement_agility|movement_reactions|movement_balance|power_shot_power|power_jumping|power_stamina|power_strength|power_long_shots|mentality_aggression|mentality_interceptions|mentality_positioning|mentality_vision|mentality_penalties|mentality_composure|defending_marking|defending_standing_tackle|defending_sliding_tackle|goalkeeping_diving|goalkeeping_handling|goalkeeping_kicking|goalkeeping_positioning|goalkeeping_reflexes| ls| st| rs| lw| lf| cf| rf| rw|lam|cam|ram| lm|lcm| cm|rcm| rm|lwb|ldm|cdm|rdm|rwb| lb|lcb| cb|rcb| rb|\n",
      "+---------+--------------------+-----------------+--------------------+---+----------+---------+---------+-----------+-------------------+-------+---------+---------+--------+----------------+--------------+------------------------+---------+-----------+-------------+---------+---------+-------------+------------------+----------+--------------------+---------------+----+--------+-------+---------+---------+------+----+------------------+-------------------+--------------------------+-----------------------+-----------------+---------------+-----------+-----------------+------------------+------------------+---------------------+---------------------+----------------+------------------+----------------+----------------+-------------+-------------+--------------+----------------+--------------------+-----------------------+---------------------+----------------+-------------------+-------------------+-----------------+-------------------------+------------------------+------------------+--------------------+-------------------+-----------------------+--------------------+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+\n",
      "|   158023|https://sofifa.co...|         L. Messi|Lionel Andrés Mes...| 27|1987-06-24|      169|       67|  Argentina|       FC Barcelona|     93|       95|        0|       0|              CF|          Left|                       5|        3|          4|   Medium/Low|   Normal|      Yes|           CF|                10|2004-07-01|                2018|             CF|  93|      89|     86|       96|       27|    63|2015|                84|                 91|                        71|                     89|               80|             95|         91|               94|                76|                96|                   96|                   92|              94|                92|              95|              79|           73|           76|            60|              88|                  48|                     22|                   91|              90|                 76|                 58|               25|                       21|                      20|                 6|                  11|                 15|                     14|                   8| 92| 92| 92| 95| 93| 93| 93| 95| 95| 95| 95| 93| 82| 82| 82| 93| 65| 65| 65| 65| 65| 57| 48| 48| 48| 57|\n",
      "|    20801|https://sofifa.co...|Cristiano Ronaldo|Cristiano Ronaldo...| 29|1985-02-05|      185|       80|   Portugal|        Real Madrid|     92|       92|        0|       0|          LW, LM|         Right|                       5|        4|          5|     High/Low|   Normal|      Yes|           LW|                 7|2009-07-01|                2018|             LW|  93|      93|     81|       91|       32|    79|2015|                83|                 98|                        86|                     82|               89|             96|         88|               79|                72|                89|                   91|                   94|              93|                90|              51|              94|           94|           89|            79|              93|                  63|                     24|                   93|              81|                 85|                 58|               22|                       31|                      23|                 7|                  11|                 15|                     14|                  11| 94| 94| 94| 92| 94| 94| 94| 92| 92| 92| 92| 90| 80| 80| 80| 90| 66| 66| 66| 66| 66| 60| 55| 55| 55| 60|\n",
      "|     9014|https://sofifa.co...|        A. Robben|        Arjen Robben| 30|1984-01-23|      180|       80|Netherlands|  FC Bayern München|     90|       90|        0|       0|      RM, LM, RW|          Left|                       5|        2|          4|     High/Low|   Normal|      Yes|          SUB|                10|2009-08-28|                2017|             RS|  93|      86|     83|       92|       32|    64|2015|                80|                 87|                        50|                     88|               88|             93|         85|               82|                79|                91|                   93|                   95|              94|                91|              91|              86|           61|           89|            65|              91|                  56|                     40|                   91|              86|                 81|                 58|               29|                       28|                      27|                10|                   8|                 11|                      5|                  15| 87| 87| 87| 91| 90| 90| 90| 91| 91| 91| 91| 90| 81| 81| 81| 90| 67| 67| 67| 67| 67| 58| 49| 49| 49| 58|\n",
      "|    41236|https://sofifa.co...|   Z. Ibrahimović|  Zlatan Ibrahimović| 32|1981-10-03|      195|       95|     Sweden|Paris Saint-Germain|     90|       90|        0|       0|              ST|         Right|                       5|        4|          4|   Medium/Low|   Normal|      Yes|           ST|                10|2012-07-01|                2016|             ST|  76|      91|     81|       86|       34|    86|2015|                76|                 91|                        76|                     82|               95|             88|         80|               80|                80|                90|                   76|                   76|              86|                85|              41|              93|           72|           78|            93|              88|                  84|                     20|                   86|              82|                 91|                 58|               25|                       33|                      27|                13|                  15|                 10|                      9|                  12| 90| 90| 90| 87| 89| 89| 89| 87| 89| 89| 89| 86| 79| 79| 79| 86| 64| 68| 68| 68| 64| 59| 58| 58| 58| 59|\n",
      "|   167495|https://sofifa.co...|         M. Neuer|        Manuel Neuer| 28|1986-03-27|      193|       92|    Germany|  FC Bayern München|     90|       90|        0|       0|              GK|         Right|                       5|        4|          1|Medium/Medium|   Normal|      Yes|           GK|                 1|2011-07-01|                2019|             GK|null|    null|   null|     null|     null|  null|2015|                25|                 25|                        25|                     42|               25|             25|         25|               25|                41|                31|                   66|                   68|              47|                92|              35|              42|           78|           53|            88|              25|                  32|                     38|                   25|              20|                 37|                 58|               25|                       25|                      25|                87|                  88|                 92|                     96|                  86| 59| 59| 59| 60| 59| 59| 59| 60| 60| 60| 60| 61| 59| 59| 59| 61| 58| 58| 58| 58| 58| 57| 56| 56| 56| 57|\n",
      "+---------+--------------------+-----------------+--------------------+---+----------+---------+---------+-----------+-------------------+-------+---------+---------+--------+----------------+--------------+------------------------+---------+-----------+-------------+---------+---------+-------------+------------------+----------+--------------------+---------------+----+--------+-------+---------+---------+------+----+------------------+-------------------+--------------------------+-----------------------+-----------------+---------------+-----------+-----------------+------------------+------------------+---------------------+---------------------+----------------+------------------+----------------+----------------+-------------+-------------+--------------+----------------+--------------------+-----------------------+---------------------+----------------+-------------------+-------------------+-----------------+-------------------------+------------------------+------------------+--------------------+-------------------+-----------------------+--------------------+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import regexp_extract, col\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession, SQLContext\n",
    "from pyspark.sql.functions import to_date, col, count, when, isnan, regexp_replace\n",
    "from pyspark.ml.feature import Imputer\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark import SparkContext, SparkConf, SQLContext\n",
    "import os\n",
    "\n",
    "def task1():\n",
    "    try:\n",
    "        appName = \"Big Data Analytics\"\n",
    "        master = \"local\"\n",
    "\n",
    "        # Create Configuration object for Spark.\n",
    "        conf = pyspark.SparkConf()\\\n",
    "            .set('spark.driver.host','127.0.0.1')\\\n",
    "            .setAppName(appName)\\\n",
    "            .setMaster(master)\\\n",
    "            .set(\"spark.driver.extraJavaOptions\", \"-Xss4M\")\n",
    "\n",
    "        # Create Spark Context with the new configurations rather than rely on the default one\n",
    "        sc = SparkContext.getOrCreate(conf=conf)\n",
    "\n",
    "        # You need to create SQL Context to conduct some database operations like what we will see later.\n",
    "        sqlContext = SQLContext(sc)\n",
    "\n",
    "        # If you have SQL context, you create the session from the Spark Context\n",
    "        spark = sqlContext.sparkSession.builder.config('spark.sql.codegen.wholeStage', 'false').getOrCreate()\n",
    "\n",
    "        #Ingest data from the players.csv into Spark Dataframe. \n",
    "        players_15_df = (spark.read\n",
    "                 .format(\"csv\")\n",
    "                 .option(\"inferSchema\", \"true\")\n",
    "                 .option(\"header\",\"true\")\n",
    "                 .load(\"/Users/wyc/players_15.csv\")\n",
    "              )\n",
    "        players_15_df = players_15_df.withColumn(\"year\",lit(2015))\n",
    "\n",
    "        players_16_df = (spark.read\n",
    "                 .format(\"csv\")\n",
    "                 .option(\"inferSchema\", \"true\")\n",
    "                 .option(\"header\",\"true\")\n",
    "                 .load(\"/Users/wyc/players_16.csv\")\n",
    "              )\n",
    "        players_16_df = players_16_df.withColumn(\"year\",lit(2016))\n",
    "\n",
    "        players_17_df = (spark.read\n",
    "                 .format(\"csv\")\n",
    "                 .option(\"inferSchema\", \"true\")\n",
    "                 .option(\"header\",\"true\")\n",
    "                 .load(\"/Users/wyc/players_17.csv\")\n",
    "              )\n",
    "        players_17_df = players_17_df.withColumn(\"year\",lit(2017))\n",
    "\n",
    "        players_18_df = (spark.read\n",
    "                 .format(\"csv\")\n",
    "                 .option(\"inferSchema\", \"true\")\n",
    "                 .option(\"header\",\"true\")\n",
    "                 .load(\"/Users/wyc/players_18.csv\")\n",
    "              )\n",
    "        players_18_df = players_18_df.withColumn(\"year\",lit(2018))\n",
    "\n",
    "        players_19_df = (spark.read\n",
    "                 .format(\"csv\")\n",
    "                 .option(\"inferSchema\", \"true\")\n",
    "                 .option(\"header\",\"true\")\n",
    "                 .load(\"/Users/wyc/players_19.csv\")\n",
    "              )\n",
    "        players_19_df = players_19_df.withColumn(\"year\",lit(2019))\n",
    "\n",
    "        players_20_df = (spark.read\n",
    "                 .format(\"csv\")\n",
    "                 .option(\"inferSchema\", \"true\")\n",
    "                 .option(\"header\",\"true\")\n",
    "                 .load(\"/Users/wyc/players_20.csv\")\n",
    "              )\n",
    "        players_20_df = players_20_df.withColumn(\"year\",lit(2020))\n",
    "    except TypeError:\n",
    "        print(\"Failed to load the data\")\n",
    "    merged_df = players_15_df.union(players_16_df).union(players_17_df)\\\n",
    "            .union(players_18_df).union(players_19_df).union(players_20_df)\n",
    "    full_df = merged_df\n",
    "    total_rows = full_df.count()\n",
    "    th = total_rows / 2\n",
    "    variables = ['sofifa_id','player_url','short_name','long_name','age','dob','height_cm','weight_kg','nationality','club','overall','potential','value_eur','wage_eur','player_positions','preferred_foot','international_reputation','weak_foot','skill_moves','work_rate','body_type','real_face','release_clause_eur','player_tags','team_position','team_jersey_number','loaned_from','joined','contract_valid_until','nation_position','nation_jersey_number','pace','shooting','passing','dribbling','defending','physic','gk_diving','gk_handling','gk_kicking','gk_reflexes','gk_speed','gk_positioning','player_traits','attacking_crossing','attacking_finishing','attacking_heading_accuracy','attacking_short_passing','attacking_volleys','skill_dribbling','skill_curve','skill_fk_accuracy','skill_long_passing','skill_ball_control','movement_acceleration','movement_sprint_speed','movement_agility','movement_reactions','movement_balance','power_shot_power','power_jumping','power_stamina','power_strength','power_long_shots','mentality_aggression','mentality_interceptions','mentality_positioning','mentality_vision','mentality_penalties','mentality_composure','defending_marking','defending_standing_tackle','defending_sliding_tackle','goalkeeping_diving','goalkeeping_handling','goalkeeping_kicking','goalkeeping_positioning','goalkeeping_reflexes','ls','st','rs','lw','lf','cf','rf','rw','lam','cam','ram','lm','lcm','cm','rcm','rm','lwb','ldm','cdm','rdm','rwb','lb','lcb','cb','rcb','rb','year']\n",
    "    dropped = list(variables[i] for i in [22,23,26,30,37,38,39,40,41,42,43])\n",
    "    for v in dropped:\n",
    "        full_df = full_df.drop(col(v))\n",
    "    skills = ['attacking_crossing','attacking_finishing','attacking_heading_accuracy','attacking_short_passing','attacking_volleys','skill_dribbling','skill_curve','skill_fk_accuracy','skill_long_passing','skill_ball_control','movement_acceleration','movement_sprint_speed','movement_agility','movement_reactions','movement_balance','power_shot_power','power_jumping','power_stamina','power_strength','power_long_shots','mentality_aggression','mentality_interceptions','mentality_positioning','mentality_vision','mentality_penalties','mentality_composure','defending_marking','defending_standing_tackle','defending_sliding_tackle','goalkeeping_diving','goalkeeping_handling','goalkeeping_kicking','goalkeeping_positioning','goalkeeping_reflexes','ls','st','rs','lw','lf','cf','rf','rw','lam','cam','ram','lm','lcm','cm','rcm','rm','lwb','ldm','cdm','rdm','rwb','lb','lcb','cb','rcb','rb']\n",
    "    for name in skills:\n",
    "        main = name + '_main'\n",
    "        plus = name + '_plus'\n",
    "        minus = name + '_minus'\n",
    "        new = name + '_c'\n",
    "        full_df = full_df\\\n",
    "            .withColumn(main,regexp_extract(col(name), '^([0-9]+)', 1).cast(\"integer\"))\\\n",
    "            .withColumn(\"tmp1\",regexp_extract(col(name), '^([0-9]+)\\+([0-9]+)', 2).cast(\"integer\"))\\\n",
    "            .withColumn(\"tmp2\",regexp_extract(col(name), '^([0-9]+)\\-([0-9]+)', 2).cast(\"integer\"))\\\n",
    "            .withColumn(plus, when(col('tmp1').isNull(),0).otherwise(col('tmp1')).cast(\"integer\"))\\\n",
    "            .withColumn(minus, when(col('tmp2').isNull(),0).otherwise(col('tmp2')).cast(\"integer\"))\\\n",
    "            .withColumn(new, col(main)+col(plus)-col(minus))\n",
    "    # here cast integer is important since it will transform \"\" to Null\n",
    "        full_df = full_df\\\n",
    "            .drop(col(main))\\\n",
    "            .drop(col('tmp1'))\\\n",
    "            .drop(col('tmp2'))\\\n",
    "            .drop(col(plus))\\\n",
    "            .drop(col(minus))\\\n",
    "            .drop(col(name))\\\n",
    "            .withColumnRenamed(new,name)\n",
    "    imputer = Imputer (\n",
    "    inputCols=skills,\n",
    "    outputCols=[\"{}_imputed\".format(c) for c in skills]\n",
    "    ).setStrategy(\"mean\").setMissingValue(0)\n",
    "    full_imputed_df = imputer.fit(full_df).transform(full_df)\n",
    "    for name in skills:\n",
    "        newname = name + '_imputed'\n",
    "        full_imputed_df = full_imputed_df.drop(name)\n",
    "        full_imputed_df = full_imputed_df.withColumnRenamed(newname,name)\n",
    "    db_properties={}\n",
    "    db_properties['username']=\"postgres\"\n",
    "    db_properties['password']=\"990331\"\n",
    "    # make sure to use the correct port number. These \n",
    "    db_properties['url']= \"jdbc:postgresql://localhost:5432/postgres\"\n",
    "    db_properties['driver']=\"org.postgresql.Driver\"\n",
    "    full_imputed_df.write.format(\"jdbc\")\\\n",
    "    .mode(\"overwrite\")\\\n",
    "    .option(\"url\", \"jdbc:postgresql://localhost:5432/postgres\")\\\n",
    "    .option(\"dbtable\", \"fifa.player_info\")\\\n",
    "    .option(\"user\", \"postgres\")\\\n",
    "    .option(\"password\", \"990331\")\\\n",
    "    .option(\"Driver\", \"org.postgresql.Driver\")\\\n",
    "    .save()\n",
    "    return full_imputed_df\n",
    "task1()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "19b2c26a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 579:>                                                        (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Adam Smith',\n",
       " 'Liam Kelly',\n",
       " 'Tom Davies',\n",
       " 'Mohammed Al Buraik',\n",
       " 'Abdulrahman Al Ghamdi']"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parameters: year1, year2, x\n",
    "# year1, year2, the year used to select the players who improve the most. year2 is the more recent year\n",
    "# x, number of players that will be selected\n",
    "# Return: return list of players who improve the most\n",
    "# Description: The function select top x players who improve the most.\n",
    "def task2_1(year1,year2,x):\n",
    "    if year1 not in [2015,2016,2017,2018,2019,2020]:\n",
    "        return \"Invalid\"\n",
    "    if year2 not in [2015,2016,2017,2018,2019,2020]:\n",
    "        return \"Invalid\"\n",
    "    if year1>year2:\n",
    "        return \"Invalid\"\n",
    "    if isinstance(x,int)==False:\n",
    "        return \"Invalid\"\n",
    "    if x<=0:\n",
    "        return \"Invalid\"\n",
    "    try:\n",
    "        appName = \"Big Data Analytics\"\n",
    "        master = \"local\"\n",
    "        # Create Configuration object for Spark.\n",
    "        conf = pyspark.SparkConf()\\\n",
    "            .set('spark.driver.host','127.0.0.1')\\\n",
    "            .setAppName(appName)\\\n",
    "            .setMaster(master)\\\n",
    "            .set(\"spark.driver.extraJavaOptions\", \"-Xss4M\")\n",
    "\n",
    "        # Create Spark Context with the new configurations rather than rely on the default one\n",
    "        sc = SparkContext.getOrCreate(conf=conf)\n",
    "\n",
    "        # You need to create SQL Context to conduct some database operations like what we will see later.\n",
    "        sqlContext = SQLContext(sc)\n",
    "\n",
    "        # If you have SQL context, you create the session from the Spark Context\n",
    "        spark = sqlContext.sparkSession.builder.config('spark.sql.codegen.wholeStage', 'false').getOrCreate()\n",
    "\n",
    "        db_properties={}\n",
    "        db_properties['username']=\"postgres\"\n",
    "        db_properties['password']=\"990331\"\n",
    "        # make sure to use the correct port number. These \n",
    "        db_properties['url']= \"jdbc:postgresql://localhost:5432/postgres\"\n",
    "        db_properties['driver']=\"org.postgresql.Driver\"\n",
    "        full_imputed_df_read = sqlContext.read.format(\"jdbc\")\\\n",
    "        .option(\"url\", \"jdbc:postgresql://localhost:5432/postgres\")\\\n",
    "        .option(\"dbtable\", \"fifa.player_info\")\\\n",
    "        .option(\"user\", \"postgres\")\\\n",
    "        .option(\"password\", \"990331\")\\\n",
    "        .option(\"Driver\", \"org.postgresql.Driver\")\\\n",
    "        .load()\n",
    "    except TypeError:\n",
    "        print(\"Failed to read the data\")\n",
    "    try:\n",
    "        df1 = full_imputed_df_read.where(full_imputed_df_read.year==year1)\n",
    "        df2 = full_imputed_df_read.where(full_imputed_df_read.year==year2)\n",
    "        df_2015_imputed_read = df1.withColumn(\"improve1\",(col(\"skill_moves\")+\n",
    "                                               col(\"skill_dribbling\")+\n",
    "                                               col(\"skill_curve\")+\n",
    "                                               col(\"skill_fk_accuracy\")+\n",
    "                                               col(\"skill_long_passing\")+\n",
    "                                               col(\"skill_ball_control\")))\n",
    "        df_2015_imputed_read = df_2015_imputed_read.select((\"long_name\"),(\"improve1\"))\n",
    "\n",
    "        df_2020_imputed_read = df2.withColumn(\"improve2\",(col(\"skill_moves\")+\n",
    "                                               col(\"skill_dribbling\")+\n",
    "                                               col(\"skill_curve\")+\n",
    "                                               col(\"skill_fk_accuracy\")+\n",
    "                                               col(\"skill_long_passing\")+\n",
    "                                               col(\"skill_ball_control\")))\n",
    "        df_2020_imputed_read = df_2020_imputed_read.select((\"long_name\"),(\"improve2\"))\n",
    "\n",
    "        df = df_2015_imputed_read.join(df_2020_imputed_read,\n",
    "                                       df_2015_imputed_read.long_name == df_2020_imputed_read.long_name,\n",
    "                                       \"inner\")\n",
    "        df = df.withColumn(\"improve\",(col(\"improve2\")-col(\"improve1\")))\n",
    "        df = df.sort(col(\"improve\").desc())\n",
    "        collect = df.collect()\n",
    "\n",
    "        l = [None] * x\n",
    "        name = [\"\"] * x\n",
    "        for i in range(x):\n",
    "            l[i] = collect[i][-1]\n",
    "            name[i] = collect[i][0]\n",
    "    except ValueError:\n",
    "        print(\"Something wrong in Calculation\")\n",
    "    return name \n",
    "task2_1(2015,2020,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "82dffff7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Boyacá Chicó FC',\n",
       " 'FC Girondins de Bordeaux',\n",
       " 'Club Atlético Banfield',\n",
       " 'River Plate',\n",
       " 'Querétaro']"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parameters: y\n",
    "# y, number of clubs that will be selected\n",
    "# Return: return list of clubs which have the most number of players with contracts ending in 2021\n",
    "# Description: The function select top y clubs which have the most number of players with contracts ending in 2021.\n",
    "def task2_2(y):\n",
    "    if isinstance(y,int)==False:\n",
    "        return \"Invalid\"\n",
    "    if y<=0:\n",
    "        return \"Invalid\"\n",
    "    try:\n",
    "        appName = \"Big Data Analytics\"\n",
    "        master = \"local\"\n",
    "        # Create Configuration object for Spark.\n",
    "        conf = pyspark.SparkConf()\\\n",
    "            .set('spark.driver.host','127.0.0.1')\\\n",
    "            .setAppName(appName)\\\n",
    "            .setMaster(master)\\\n",
    "            .set(\"spark.driver.extraJavaOptions\", \"-Xss4M\")\n",
    "        \n",
    "        # Create Spark Context with the new configurations rather than rely on the default one\n",
    "        sc = SparkContext.getOrCreate(conf=conf)\n",
    "\n",
    "        # You need to create SQL Context to conduct some database operations like what we will see later.\n",
    "        sqlContext = SQLContext(sc)\n",
    "\n",
    "        # If you have SQL context, you create the session from the Spark Context\n",
    "        spark = sqlContext.sparkSession.builder.config('spark.sql.codegen.wholeStage', 'false').getOrCreate()\n",
    "\n",
    "        db_properties={}\n",
    "        db_properties['username']=\"postgres\"\n",
    "        db_properties['password']=\"990331\"\n",
    "        # make sure to use the correct port number. These \n",
    "        db_properties['url']= \"jdbc:postgresql://localhost:5432/postgres\"\n",
    "        db_properties['driver']=\"org.postgresql.Driver\"\n",
    "        full_imputed_df_read = sqlContext.read.format(\"jdbc\")\\\n",
    "        .option(\"url\", \"jdbc:postgresql://localhost:5432/postgres\")\\\n",
    "        .option(\"dbtable\", \"fifa.player_info\")\\\n",
    "        .option(\"user\", \"postgres\")\\\n",
    "        .option(\"password\", \"990331\")\\\n",
    "        .option(\"Driver\", \"org.postgresql.Driver\")\\\n",
    "        .load()\n",
    "    except TypeError:\n",
    "        print(\"Failed to read the data\")\n",
    "    try:\n",
    "        df = full_imputed_df_read.filter(col(\"contract_valid_until\") == 2021)\n",
    "        df = df.groupBy(\"club\").count()\n",
    "        df = df.sort(col(\"count\").desc())\n",
    "\n",
    "        collect = df.collect()\n",
    "        club = [\"\"] * y\n",
    "        for i in range(y):\n",
    "            club[i] = collect[i][0]\n",
    "    except ValueError:\n",
    "        print(\"Something wrong in Calculation\")\n",
    "    return club\n",
    "task2_2(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "c44e52c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Arsenal',\n",
       " 'Southampton',\n",
       " 'Leicester City',\n",
       " 'Tottenham Hotspur',\n",
       " 'West Ham United']"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parameters: z\n",
    "# z, number of clubs that will be selected\n",
    "# Return: return list of clubs with largest number of players in the dataset where z >= 5.\n",
    "# Description: The function select top z clubs with largest number of players in the dataset where z >= 5.\n",
    "def task2_3(z,year=\"all\"):\n",
    "    if isinstance(z,int)==False:\n",
    "        return \"Invalid\"\n",
    "    if z < 5:\n",
    "        print(\"z is not big enough\")\n",
    "        return \"z is not big enough\"\n",
    "    try:\n",
    "        appName = \"Big Data Analytics\"\n",
    "        master = \"local\"\n",
    "        # Create Configuration object for Spark.\n",
    "        conf = pyspark.SparkConf()\\\n",
    "            .set('spark.driver.host','127.0.0.1')\\\n",
    "            .setAppName(appName)\\\n",
    "            .setMaster(master)\\\n",
    "            .set(\"spark.driver.extraJavaOptions\", \"-Xss4M\")\n",
    "\n",
    "        # Create Spark Context with the new configurations rather than rely on the default one\n",
    "        sc = SparkContext.getOrCreate(conf=conf)\n",
    "\n",
    "        # You need to create SQL Context to conduct some database operations like what we will see later.\n",
    "        sqlContext = SQLContext(sc)\n",
    "\n",
    "        # If you have SQL context, you create the session from the Spark Context\n",
    "        spark = sqlContext.sparkSession.builder.config('spark.sql.codegen.wholeStage', 'false').getOrCreate()\n",
    "\n",
    "        db_properties={}\n",
    "        db_properties['username']=\"postgres\"\n",
    "        db_properties['password']=\"990331\"\n",
    "        # make sure to use the correct port number. These \n",
    "        db_properties['url']= \"jdbc:postgresql://localhost:5432/postgres\"\n",
    "        db_properties['driver']=\"org.postgresql.Driver\"\n",
    "        full_imputed_df_read = sqlContext.read.format(\"jdbc\")\\\n",
    "        .option(\"url\", \"jdbc:postgresql://localhost:5432/postgres\")\\\n",
    "        .option(\"dbtable\", \"fifa.player_info\")\\\n",
    "        .option(\"user\", \"postgres\")\\\n",
    "        .option(\"password\", \"990331\")\\\n",
    "        .option(\"Driver\", \"org.postgresql.Driver\")\\\n",
    "        .load()\n",
    "        if year == \"all\":\n",
    "            full_imputed_df_read = full_imputed_df_read\n",
    "        elif year in [2015,2016,2017,2018,2019,2020]:\n",
    "            full_imputed_df_read = full_imputed_df_read.filter(col(\"year\") == year)\n",
    "        else: \n",
    "            return \"invalid input\"\n",
    "    except TypeError:\n",
    "        print(\"Failed to read the data\")\n",
    "    try:\n",
    "        df = full_imputed_df_read.groupBy(\"club\").count()\n",
    "        df = df.sort(col(\"count\").desc())\n",
    "\n",
    "        is_false = True\n",
    "\n",
    "        collect = df.collect()\n",
    "        club = [\"\"] * z\n",
    "        club[0] = collect[0][0]\n",
    "        count = [None] * z\n",
    "        count[0] = collect[0][1]\n",
    "        for i in range(1,z):\n",
    "            club[i] = collect[i][0]\n",
    "            count[i] = collect[i][1]\n",
    "            if count[i-1] != count[i]:\n",
    "                is_false = False\n",
    "    except ValueError:\n",
    "        print(\"Something wrong in Calculation\")\n",
    "    \n",
    "    if is_false == True:\n",
    "        return \"All the same\"\n",
    "    else:\n",
    "        return club\n",
    "task2_3(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "f37dc97f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SUB'"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def task2_4_1(year = \"all\"):\n",
    "    try:\n",
    "        appName = \"Big Data Analytics\"\n",
    "        master = \"local\"\n",
    "        # Create Configuration object for Spark.\n",
    "        conf = pyspark.SparkConf()\\\n",
    "            .set('spark.driver.host','127.0.0.1')\\\n",
    "            .setAppName(appName)\\\n",
    "            .setMaster(master)\\\n",
    "            .set(\"spark.driver.extraJavaOptions\", \"-Xss4M\")\n",
    "\n",
    "        # Create Spark Context with the new configurations rather than rely on the default one\n",
    "        sc = SparkContext.getOrCreate(conf=conf)\n",
    "\n",
    "        # You need to create SQL Context to conduct some database operations like what we will see later.\n",
    "        sqlContext = SQLContext(sc)\n",
    "\n",
    "        # If you have SQL context, you create the session from the Spark Context\n",
    "        spark = sqlContext.sparkSession.builder.config('spark.sql.codegen.wholeStage', 'false').getOrCreate()\n",
    "\n",
    "        db_properties={}\n",
    "        db_properties['username']=\"postgres\"\n",
    "        db_properties['password']=\"990331\"\n",
    "        # make sure to use the correct port number. These \n",
    "        db_properties['url']= \"jdbc:postgresql://localhost:5432/postgres\"\n",
    "        db_properties['driver']=\"org.postgresql.Driver\"\n",
    "        full_imputed_df_read = sqlContext.read.format(\"jdbc\")\\\n",
    "        .option(\"url\", \"jdbc:postgresql://localhost:5432/postgres\")\\\n",
    "        .option(\"dbtable\", \"fifa.player_info\")\\\n",
    "        .option(\"user\", \"postgres\")\\\n",
    "        .option(\"password\", \"990331\")\\\n",
    "        .option(\"Driver\", \"org.postgresql.Driver\")\\\n",
    "        .load()\n",
    "        if year == \"all\":\n",
    "            full_imputed_df_read = full_imputed_df_read\n",
    "        elif year in [2015,2016,2017,2018,2019,2020]:\n",
    "            full_imputed_df_read = full_imputed_df_read.filter(col(\"year\") == year)\n",
    "        else: \n",
    "            return \"invalid input\"\n",
    "    except TypeError:\n",
    "        print(\"Failed to read the data\")\n",
    "    \n",
    "    try:\n",
    "        df = full_imputed_df_read.groupBy(\"nation_position\").count().sort(col(\"count\").desc())\n",
    "        collect = df.collect()\n",
    "    except ValueError:\n",
    "        print(\"Something wrong in Calculation\")\n",
    "    if collect[0][0]==None:\n",
    "        return collect[1][0]\n",
    "    else:\n",
    "        return collect[0][0]\n",
    "task2_4_1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "63bea6ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SUB'"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def task2_4_2(year=\"all\"):\n",
    "    try:\n",
    "        appName = \"Big Data Analytics\"\n",
    "        master = \"local\"\n",
    "        # Create Configuration object for Spark.\n",
    "        conf = pyspark.SparkConf()\\\n",
    "            .set('spark.driver.host','127.0.0.1')\\\n",
    "            .setAppName(appName)\\\n",
    "            .setMaster(master)\\\n",
    "            .set(\"spark.driver.extraJavaOptions\", \"-Xss4M\")\n",
    "\n",
    "        # Create Spark Context with the new configurations rather than rely on the default one\n",
    "        sc = SparkContext.getOrCreate(conf=conf)\n",
    "\n",
    "        # You need to create SQL Context to conduct some database operations like what we will see later.\n",
    "        sqlContext = SQLContext(sc)\n",
    "\n",
    "        # If you have SQL context, you create the session from the Spark Context\n",
    "        spark = sqlContext.sparkSession.builder.config('spark.sql.codegen.wholeStage', 'false').getOrCreate()\n",
    "\n",
    "        db_properties={}\n",
    "        db_properties['username']=\"postgres\"\n",
    "        db_properties['password']=\"990331\"\n",
    "        # make sure to use the correct port number. These \n",
    "        db_properties['url']= \"jdbc:postgresql://localhost:5432/postgres\"\n",
    "        db_properties['driver']=\"org.postgresql.Driver\"\n",
    "        full_imputed_df_read = sqlContext.read.format(\"jdbc\")\\\n",
    "        .option(\"url\", \"jdbc:postgresql://localhost:5432/postgres\")\\\n",
    "        .option(\"dbtable\", \"fifa.player_info\")\\\n",
    "        .option(\"user\", \"postgres\")\\\n",
    "        .option(\"password\", \"990331\")\\\n",
    "        .option(\"Driver\", \"org.postgresql.Driver\")\\\n",
    "        .load()\n",
    "        if year == \"all\":\n",
    "            full_imputed_df_read = full_imputed_df_read\n",
    "        elif year in [2015,2016,2017,2018,2019,2020]:\n",
    "            full_imputed_df_read = full_imputed_df_read.filter(col(\"year\") == year)\n",
    "        else: \n",
    "            return \"invalid input\"\n",
    "    except TypeError:\n",
    "        print(\"Failed to read the data\")\n",
    "    \n",
    "    try:\n",
    "        df = full_imputed_df_read.groupBy(\"team_position\").count().sort(col(\"count\").desc())\n",
    "        collect = df.collect()\n",
    "    except ValueError:\n",
    "        print(\"Something wrong in Calculation\")\n",
    "    if collect[0][0]==None:\n",
    "        return collect[1][0]\n",
    "    else:\n",
    "        return collect[0][0]\n",
    "task2_4_2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "9a2e0707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'England'"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def task2_5(year = \"all\"):\n",
    "    try:\n",
    "        appName = \"Big Data Analytics\"\n",
    "        master = \"local\"\n",
    "        # Create Configuration object for Spark.\n",
    "        conf = pyspark.SparkConf()\\\n",
    "            .set('spark.driver.host','127.0.0.1')\\\n",
    "            .setAppName(appName)\\\n",
    "            .setMaster(master)\\\n",
    "            .set(\"spark.driver.extraJavaOptions\", \"-Xss4M\")\n",
    "\n",
    "        # Create Spark Context with the new configurations rather than rely on the default one\n",
    "        sc = SparkContext.getOrCreate(conf=conf)\n",
    "\n",
    "        # You need to create SQL Context to conduct some database operations like what we will see later.\n",
    "        sqlContext = SQLContext(sc)\n",
    "\n",
    "        # If you have SQL context, you create the session from the Spark Context\n",
    "        spark = sqlContext.sparkSession.builder.config('spark.sql.codegen.wholeStage', 'false').getOrCreate()\n",
    "\n",
    "        db_properties={}\n",
    "        db_properties['username']=\"postgres\"\n",
    "        db_properties['password']=\"990331\"\n",
    "        # make sure to use the correct port number. These \n",
    "        db_properties['url']= \"jdbc:postgresql://localhost:5432/postgres\"\n",
    "        db_properties['driver']=\"org.postgresql.Driver\"\n",
    "        full_imputed_df_read = sqlContext.read.format(\"jdbc\")\\\n",
    "        .option(\"url\", \"jdbc:postgresql://localhost:5432/postgres\")\\\n",
    "        .option(\"dbtable\", \"fifa.player_info\")\\\n",
    "        .option(\"user\", \"postgres\")\\\n",
    "        .option(\"password\", \"990331\")\\\n",
    "        .option(\"Driver\", \"org.postgresql.Driver\")\\\n",
    "        .load()\n",
    "        if year == \"all\":\n",
    "            full_imputed_df_read = full_imputed_df_read\n",
    "        elif year in [2015,2016,2017,2018,2019,2020]:\n",
    "            full_imputed_df_read = full_imputed_df_read.filter(col(\"year\") == year)\n",
    "        else: \n",
    "            return \"invalid input\"\n",
    "    except TypeError:\n",
    "        print(\"Failed to read the data\")\n",
    "    \n",
    "    try:\n",
    "        df = full_imputed_df_read.groupBy(\"nationality\").count().sort(col(\"count\").desc())\n",
    "        collect = df.collect()\n",
    "    except ValueError:\n",
    "        print(\"Something wrong in calculation\")\n",
    "    return collect[0][0]\n",
    "task2_5()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "4397dd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytest\n",
    "\n",
    "def test_task1():\n",
    "    data = task1()\n",
    "    assert data is not None, \"Failed to load data\"\n",
    "    assert data.count() == 100995,\"Wrong row number\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "e992e560",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_task2_1_happy():\n",
    "    assert task2_1(2015,2016,5) == ['Scott Brown', 'Adam Smith', 'Mustafa Akbaş', 'Alvin Arrondel', 'Liam Kelly'], \"Wrong Output\"\n",
    "    assert task2_1(2015,2019,5) == ['Liam Kelly',\n",
    " 'Adam Smith',\n",
    " 'Jorge Rodríguez',\n",
    " 'Tom Davies',\n",
    " 'Abdulrahman Al Ghamdi'], \"Wrong Output\"\n",
    "    assert task2_1(2016,2017,5) == ['Scott Brown', 'Danny Ward', 'Alan Smith', 'Jorge Rodríguez', 'Adam Smith'],\"Wrong Output\"\n",
    "    assert task2_1(2015,2020,5) ==['Adam Smith',\n",
    " 'Liam Kelly',\n",
    " 'Tom Davies',\n",
    " 'Mohammed Al Buraik',\n",
    " 'Abdulrahman Al Ghamdi'] , \"Wrong Output\"\n",
    "    \n",
    "def test_task2_1_sad():\n",
    "    assert task2_1(\"Who are you\",2016,5) == \"Invalid\", \"Wrong Output\"\n",
    "    assert task2_1(2020,2015,5) == \"Invalid\", \"Wrong Output\"\n",
    "    assert task2_1(2020,2015,0.2) == \"Invalid\", \"Wrong Output\"\n",
    "    assert task2_1(2020,2015,\"apple\") == \"Invalid\", \"Wrong Output\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "4196b7ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "def test_task2_2_happy():\n",
    "    assert task2_2(5) == ['Boyacá Chicó FC',\n",
    " 'FC Girondins de Bordeaux',\n",
    " 'Club Atlético Banfield',\n",
    " 'River Plate',\n",
    " 'Querétaro'],\"Wrong Output\"\n",
    "    assert task2_2(7) == ['Boyacá Chicó FC',\n",
    " 'FC Girondins de Bordeaux',\n",
    " 'Club Atlético Banfield',\n",
    " 'River Plate',\n",
    " 'Querétaro',\n",
    " 'Club América',\n",
    " 'Newcastle United'],\"Wrong Output\"\n",
    "def test_task2_2_sad():\n",
    "    assert task2_2(0) == \"Invalid\" ,\"Wrong Output\"\n",
    "    assert task2_2(\"ss\") == \"Invalid\" ,\"Wrong Output\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f35b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_task2_3_happy():\n",
    "    assert task2_3(10,\"all\") == ['Arsenal',\n",
    " 'Southampton',\n",
    " 'Leicester City',\n",
    " 'Tottenham Hotspur',\n",
    " 'West Ham United',\n",
    " 'Crystal Palace',\n",
    " 'Manchester City',\n",
    " 'Lazio',\n",
    " 'Chelsea', \n",
    " 'Everton'],\"Wrong Output\"\n",
    "    assert task2_3(10,2020) == 'All the same',\"Wrong Output\"\n",
    "    assert task2_3(10,2019) == 'All the same',\"Wrong Output\"\n",
    "    assert task2_3(6) == ['Arsenal',\n",
    " 'Southampton',\n",
    " 'Leicester City',\n",
    " 'Tottenham Hotspur',\n",
    " 'West Ham United',\n",
    " 'Crystal Palace']\n",
    "def test_task2_3_sad():\n",
    "    assert task2_3(10,\"alffasdl\") == \"invalid input\",\"Wrong Output\"\n",
    "    assert task2_3(1,2020) == 'z is not big enough',\"Wrong Output\"\n",
    "    assert task2_3(\"d\",2019) == 'Invalid',\"Wrong Output\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e3c6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_task2_4_1_happy():\n",
    "    assert task2_4_1(2019) == 'SUB',\"Wrong Output\"\n",
    "    assert task2_4_1() == 'SUB',\"Wrong Output\"\n",
    "    assert task2_4_1(2017) == 'SUB',\"Wrong Output\"\n",
    "def test_task2_4_1_sad():\n",
    "    assert task2_4_1(\"df\") == \"invalid input\",\"Wrong Output\"\n",
    "    assert task2_4_1(21) == \"invalid input\",\"Wrong Output\"\n",
    "    assert task2_4_1(2038) == \"invalid input\",\"Wrong Output\"\n",
    "def test_task2_4_2_happy():\n",
    "    assert task2_4_2(2019) == 'SUB',\"Wrong Output\"\n",
    "    assert task2_4_2() == 'SUB',\"Wrong Output\"\n",
    "    assert task2_4_2(2017) == 'SUB',\"Wrong Output\"\n",
    "def test_task2_4_2_sad():\n",
    "    assert task2_4_2(\"Df\") == \"invalid input\",\"Wrong Output\"\n",
    "    assert task2_4_2(22) == \"invalid input\",\"Wrong Output\"\n",
    "    assert task2_4_2(3333) == \"invalid input\",\"Wrong Output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6abef03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_task2_5_happy():\n",
    "    assert task2_5(2019) == 'England',\"Wrong Output\"\n",
    "    assert task2_5() == 'England',\"Wrong Output\"\n",
    "    assert task2_5(2017) == 'England',\"Wrong Output\"\n",
    "def test_task2_5_sad():\n",
    "    assert task2_5(\"df\") == \"invalid input\",\"Wrong Output\"\n",
    "    assert task2_5(21) == \"invalid input\",\"Wrong Output\"\n",
    "    assert task2_5(2038) == \"invalid input\",\"Wrong Output\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
